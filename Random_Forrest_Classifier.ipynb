{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efd990-ac08-4a44-9193-0d83d58aa9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import duckdb as db\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from matplotlib.collections import QuadMesh\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620eb9e-5edd-42d3-b06c-3b7ecc017072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Full_match_outcome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66251499-ae92-48d1-8a3e-7aa37ad225da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ead4e8-a668-465d-82f8-594492f31a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0586da-d78c-410b-b24f-ebc1fe904646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# use index-based sampling since we have time series data\n",
    "train, test = train_test_split(df, test_size=0.4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f8560-f454-4ed9-9936-7765a9e4515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vars = ['t1_t1_entropy','t2_t2_entropy', 't1_t2_entropy', 't2_t1_entropy']\n",
    "y_var = 'home_win'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552b479-37a7-42d8-9a35-1deccc90ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
    "dtree.fit(train[pred_vars], train[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab798dc0-469b-4784-8a96-d5385b56fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(train[pred_vars], train[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b54ec-ad4a-43e6-b4cb-323358d29af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=500, n_iter_no_change=20)\n",
    "mlp.fit(train[pred_vars], train[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f3060-16f6-462c-bf5a-925014be4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(train[pred_vars], train[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559d74a-cd6d-44e9-a713-7599a6e0b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train[pred_vars], train[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ff90c-64c6-4c26-8225-4648771d9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsClassifier()\n",
    "knr.fit(train[pred_vars], train[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1b712-c25f-4124-b245-8ec143d248d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = [dtree, rf, mlp, nb, lr, knr] #took svc out, and knr, sgd\n",
    "\n",
    "# empty dataframe to store the results\n",
    "result_table = pd.DataFrame(columns=['classifier_name', 'fpr','tpr','auc', \n",
    "                                     'log_loss', 'clf_report'])\n",
    "\n",
    "for clf in fitted:\n",
    "    # print the name of the classifier\n",
    "    print(clf.__class__.__name__)\n",
    "    \n",
    "    # get predictions\n",
    "\n",
    "    yproba = clf.predict_proba(test[pred_vars])\n",
    "    yclass = clf.predict(test[pred_vars])\n",
    "    \n",
    "    # auc information\n",
    "    fpr, tpr, _ = metrics.roc_curve(test[y_var],  yproba[:,1])\n",
    "    auc = metrics.roc_auc_score(test[y_var], yproba[:,1])\n",
    "    \n",
    "    # log loss\n",
    "    log_loss = metrics.log_loss(test[y_var], yproba[:,1])\n",
    "    \n",
    "    # add some other stats based on confusion matrix\n",
    "    clf_report = metrics.classification_report(test[y_var], yclass)\n",
    "    \n",
    "    # add the results to the dataframe\n",
    "    result_table = result_table.append({'classifier_name':clf.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc,\n",
    "                                        'log_loss': log_loss,\n",
    "                                        'clf_report': clf_report}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebab9e-77f7-46e1-bd5f-d42395a19af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.set_index('classifier_name', inplace=True)\n",
    "display(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987140e-4fc5-47aa-ba24-75e90159f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result_table.index:\n",
    "    print('\\n---- statistics for', i, \"----\\n\")\n",
    "    print(result_table.loc[i, 'clf_report'])\n",
    "    print(\"Model log loss:\", result_table.loc[i, 'log_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fc213-7ee5-4cfe-9b2a-85ee7c2940a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,12))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59e1d2-23b8-4b38-9525-eee85fb84687",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = dtree.predict(test.loc[:, pred_vars])\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', file='dtree_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db720abe-213f-44eb-8a25-28251238f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf.predict(test.loc[:, pred_vars])\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', title='Random Forrest Confusion Matrix', file='rf_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b22814-a199-417d-8722-aef2ec005401",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = mlp.predict(test.loc[:, pred_vars])\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', title='MLP Confusion Matrix', file='MLP_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5af30-cad8-44c5-a2b5-591c558293ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = nb.predict(test.loc[:, pred_vars])\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', title='Naive Bayes Confusion Matrix', file='nb_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39f59f-a329-4131-a893-21ce144d084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lr.predict(test.loc[:, pred_vars])\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', title='Linear Regression Confusion Matrix', file='lr_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23fe96-6043-43d0-84de-53f114aa7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = knr.predict(test.loc[:, pred_vars])\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', title='KNearest Neighbors Confusion Matrix', file='knr_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd0bf6-72c2-44eb-ad30-07f66882a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = test['Home_Win_Pred']\n",
    "cm = metrics.confusion_matrix(y_true=test[y_var], y_pred=predicted, labels=[1, 0])\n",
    "df_cm = pd.DataFrame(cm,  columns=['Actual Win','Actual No Win'], index=['Predicted Win', 'Predicted No Win'])\n",
    "pp_matrix(df_cm,cmap='copper', title='SEI Confusion Matrix', file='SEI_cm.png') #Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d02323-7cec-432e-9462-39640f7c97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configcell_text_and_colors(\n",
    "    array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0\n",
    "):\n",
    "    \"\"\"\n",
    "    config cell text and colors\n",
    "    and return text elements to add and to dell\n",
    "    @TODO: use fmt\n",
    "    \"\"\"\n",
    "    text_add = []\n",
    "    text_del = []\n",
    "    cell_val = array_df[lin][col]\n",
    "    tot_all = array_df[-1][-1]\n",
    "    per = (float(cell_val) / tot_all) * 100\n",
    "    curr_column = array_df[:, col]\n",
    "    ccl = len(curr_column)\n",
    "\n",
    "    # last line  and/or last column\n",
    "    if (col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "        # tots and percents\n",
    "        if cell_val != 0:\n",
    "            if (col == ccl - 1) and (lin == ccl - 1):\n",
    "                tot_rig = 0\n",
    "                for i in range(array_df.shape[0] - 1):\n",
    "                    tot_rig += array_df[i][i]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif col == ccl - 1:\n",
    "                tot_rig = array_df[lin][lin]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif lin == ccl - 1:\n",
    "                tot_rig = array_df[col][col]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            per_err = 100 - per_ok\n",
    "        else:\n",
    "            per_ok = per_err = 0\n",
    "\n",
    "        per_ok_s = [\"%.2f%%\" % (per_ok), \"100%\"][per_ok == 100]\n",
    "\n",
    "        # text to DEL\n",
    "        text_del.append(oText)\n",
    "\n",
    "        # text to ADD\n",
    "        font_prop = fm.FontProperties(weight=\"bold\", size=fz)\n",
    "        text_kwargs = dict(\n",
    "            color=\"w\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            gid=\"sum\",\n",
    "            fontproperties=font_prop,\n",
    "        )\n",
    "        lis_txt = [\"%d\" % (cell_val), per_ok_s, \"%.2f%%\" % (per_err)]\n",
    "        lis_kwa = [text_kwargs]\n",
    "        dic = text_kwargs.copy()\n",
    "        dic[\"color\"] = \"g\"\n",
    "        lis_kwa.append(dic)\n",
    "        dic = text_kwargs.copy()\n",
    "        dic[\"color\"] = \"r\"\n",
    "        lis_kwa.append(dic)\n",
    "        lis_pos = [\n",
    "            (oText._x, oText._y - 0.3),\n",
    "            (oText._x, oText._y),\n",
    "            (oText._x, oText._y + 0.3),\n",
    "        ]\n",
    "        for i in range(len(lis_txt)):\n",
    "            newText = dict(\n",
    "                x=lis_pos[i][0],\n",
    "                y=lis_pos[i][1],\n",
    "                text=lis_txt[i],\n",
    "                kw=lis_kwa[i],\n",
    "            )\n",
    "            text_add.append(newText)\n",
    "\n",
    "        # set background color for sum cells (last line and last column)\n",
    "        carr = [0.27, 0.30, 0.27, 1.0]\n",
    "        if (col == ccl - 1) and (lin == ccl - 1):\n",
    "            carr = [0.17, 0.20, 0.17, 1.0]\n",
    "        facecolors[posi] = carr\n",
    "\n",
    "    else:\n",
    "        if per > 0:\n",
    "            txt = \"%s\\n%.2f%%\" % (cell_val, per)\n",
    "        else:\n",
    "            if show_null_values == 0:\n",
    "                txt = \"\"\n",
    "            elif show_null_values == 1:\n",
    "                txt = \"0\"\n",
    "            else:\n",
    "                txt = \"0\\n0.0%\"\n",
    "        oText.set_text(txt)\n",
    "\n",
    "        # main diagonal\n",
    "        if col == lin:\n",
    "            # set color of the textin the diagonal to white\n",
    "            oText.set_color(\"w\")\n",
    "            # set background color in the diagonal to blue\n",
    "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "        else:\n",
    "            oText.set_color(\"r\")\n",
    "\n",
    "    return text_add, text_del\n",
    "\n",
    "\n",
    "def get_new_fig(fn, figsize=[9, 9]):\n",
    "    \"\"\"Init graphics\"\"\"\n",
    "    fig1 = plt.figure(fn, figsize)\n",
    "    ax1 = fig1.gca()  # Get Current Axis\n",
    "    ax1.cla()  # clear existing plot\n",
    "    return fig1, ax1\n",
    "\n",
    "def insert_totals(df_cm):\n",
    "    \"\"\"insert total column and line (the last ones)\"\"\"\n",
    "    sum_col = []\n",
    "    for c in df_cm.columns:\n",
    "        sum_col.append(df_cm[c].sum())\n",
    "    sum_lin = []\n",
    "    for item_line in df_cm.iterrows():\n",
    "        sum_lin.append(item_line[1].sum())\n",
    "    df_cm[\"sum_lin\"] = sum_lin\n",
    "    sum_col.append(np.sum(sum_lin))\n",
    "    df_cm.loc[\"sum_col\"] = sum_col\n",
    "    \n",
    "def pp_matrix(\n",
    "    df_cm,\n",
    "    annot=True,\n",
    "    cmap=\"Oranges\",\n",
    "    fmt=\".2f\",\n",
    "    fz=11,\n",
    "    lw=0.5,\n",
    "    cbar=False,\n",
    "    figsize=[8, 8],\n",
    "    show_null_values=0,\n",
    "    pred_val_axis=\"y\",\n",
    "    title=\"Confusion matrix\",\n",
    "    file=''\n",
    "):\n",
    "    \"\"\"\n",
    "    print conf matrix with default layout (like matlab)\n",
    "    params:\n",
    "      df_cm          dataframe (pandas) without totals\n",
    "      annot          print text in each cell\n",
    "      cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "      fz             fontsize\n",
    "      lw             linewidth\n",
    "      pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                      'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                      'lin' or 'y': show predicted values in lines   (y axis)\n",
    "    \"\"\"\n",
    "    if pred_val_axis in (\"col\", \"x\"):\n",
    "        xlbl = \"Predicted\"\n",
    "        ylbl = \"Actual\"\n",
    "    else:\n",
    "        xlbl = \"Actual\"\n",
    "        ylbl = \"Predicted\"\n",
    "        df_cm = df_cm.T\n",
    "\n",
    "    # create \"Total\" column\n",
    "    insert_totals(df_cm)\n",
    "\n",
    "    # this is for print allways in the same window\n",
    "    fig, ax1 = get_new_fig(\"Conf matrix default\", figsize)\n",
    "\n",
    "    ax = sn.heatmap(\n",
    "        df_cm,\n",
    "        annot=annot,\n",
    "        annot_kws={\"size\": fz},\n",
    "        linewidths=lw,\n",
    "        ax=ax1,\n",
    "        cbar=cbar,\n",
    "        cmap=cmap,\n",
    "        linecolor=\"w\",\n",
    "        fmt=fmt,\n",
    "    )\n",
    "\n",
    "    # set ticklabels rotation\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=25, fontsize=10)\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # face colors list\n",
    "    quadmesh = ax.findobj(QuadMesh)[0]\n",
    "    facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "    # iter in text elements\n",
    "    array_df = np.array(df_cm.to_records(index=False).tolist())\n",
    "    text_add = []\n",
    "    text_del = []\n",
    "    posi = -1  # from left to right, bottom to top.\n",
    "    for t in ax.collections[0].axes.texts:  # ax.texts:\n",
    "        pos = np.array(t.get_position()) - [0.5, 0.5]\n",
    "        lin = int(pos[1])\n",
    "        col = int(pos[0])\n",
    "        posi += 1\n",
    "\n",
    "        # set text\n",
    "        txt_res = configcell_text_and_colors(\n",
    "            array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values\n",
    "        )\n",
    "\n",
    "        text_add.extend(txt_res[0])\n",
    "        text_del.extend(txt_res[1])\n",
    "\n",
    "    # remove the old ones\n",
    "    for item in text_del:\n",
    "        item.remove()\n",
    "    # append the new ones\n",
    "    for item in text_add:\n",
    "        ax.text(item[\"x\"], item[\"y\"], item[\"text\"], **item[\"kw\"])\n",
    "\n",
    "    # titles and legends\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlbl)\n",
    "    ax.set_ylabel(ylbl)\n",
    "    plt.tight_layout()  # set layout slim\n",
    "    plt.show()\n",
    "    if file != '':\n",
    "        fig.savefig(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c47a7f-bb0b-4cb0-8e6e-a1d24b7b5654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
